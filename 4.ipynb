{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "project4 .ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfd0O10BCezL"
      },
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "import pandas_datareader.data as web\n",
        "from pandas import Series, DataFrame\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import GRU\n",
        "\n",
        "start = datetime.datetime(2010, 1, 1)                #read Google and apple data\n",
        "end = datetime.datetime(2019, 1, 1)\n",
        "dataset = web.DataReader(\"AAPL\", 'yahoo', start, end)\n",
        "dataset2 = web.DataReader(\"GOOG\", 'yahoo', start, end)\n",
        "dataset[\"Close\"] = dataset[\"Close\"].replace(',', '').astype(float)\n",
        "dataset2[\"Close\"] = dataset2[\"Close\"].replace(',', '').astype(float)\n",
        "dataset.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzJO9v6TCe4x"
      },
      "source": [
        "training_set1=dataset['Close']\n",
        "training_set1=pd.DataFrame(training_set1)\n",
        "\n",
        "r=0.1\n",
        "a=int ( len(training_set1)*(1-r))           #make 0.1 of data test set(apple)\n",
        "b=len(training_set1)\n",
        "print(a,b,a==b)\n",
        "training_set=training_set1[0:a]  \n",
        "text_set=training_set1[a:b]\n",
        "print(len(text_set))\n",
        "print(len(training_set))\n",
        "\n",
        "x=np.array(text_set)                      #save test set with no normalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-3AKwYn2ssR"
      },
      "source": [
        "training_set2=dataset2['Close']\n",
        "training_set2=pd.DataFrame(training_set2)\n",
        "\n",
        "r=0.1\n",
        "a=int ( len(training_set2)*(1-r))      #make 0.1 of data test set(google)\n",
        "b=len(training_set2)\n",
        "print(a,b,a==b)\n",
        "training_setX=training_set2[0:a]\n",
        "text_setX=training_set2[a:b]\n",
        "print(len(text_setX))\n",
        "print(len(training_setX))\n",
        "\n",
        "x1=np.array(text_setX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNzHNmySlVFb"
      },
      "source": [
        "training_set.plot( )\n",
        "text_set.plot()\n",
        "\n",
        "training_setX.plot( )\n",
        "text_setX.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXMpF3vCCe5Q"
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))       # Feature Scaling for apple\n",
        "training_set_scaled = sc.fit_transform(training_set)\n",
        "text_set_scaled = sc.transform(text_set)\n",
        "\n",
        "print(len(training_set_scaled))\n",
        "print(len(training_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LJqjGYC23C8"
      },
      "source": [
        "scX = MinMaxScaler(feature_range = (0, 1))       # Feature Scaling for google\n",
        "training_set_scaledX = scX.fit_transform(training_setX)\n",
        "text_set_scaledX = scX.transform(text_setX)\n",
        "\n",
        "# print(training_set_scaledX)\n",
        "print(len(training_setX))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Amver9HCe5x"
      },
      "source": [
        "X_train = []                                # Creating  train dataset with 30 timesteps and 1 output \n",
        "y_train = []\n",
        "r=0.1\n",
        "a=int ( len(training_set)*(1-r))\n",
        "b=len(training_set)\n",
        "day=30\n",
        "train=[]\n",
        "test=[]\n",
        "for i in range(day, b):                                                   \n",
        "    train=training_set_scaled[i-day:i, 0]                           #create \"data\" set from apple data                                           \n",
        "    train=np.column_stack((train,training_set_scaledX[i-day:i, 0]))#add google data to \"data\" set\n",
        "    X_train.append(train)\n",
        "\n",
        "    test=[]\n",
        "    test.append(training_set_scaled[i, 0])                          #add apple data to LABELS \n",
        "    test.append(training_set_scaledX[i, 0])                          #add google data to LABELS\n",
        "    y_train.append(test)\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 2))\n",
        "\n",
        "\n",
        "textX = []                                                          # Creating  TEST dataset with 30 timesteps and 1 output \n",
        "textY = []\n",
        "text_y=[]\n",
        "train=[]\n",
        "test=[]\n",
        "a=int ( len(text_set)*(1-r))\n",
        "b=len(text_set)\n",
        "for i in range(day, b):                                             \n",
        "    train=text_set_scaled[i-day:i, 0]                                #create \"data\" set from apple data \n",
        "    train=np.column_stack((train,text_set_scaledX[i-day:i, 0]))      #add google data to \"data\" set\n",
        "    textX.append(train)\n",
        "    test=[]\n",
        "    test.append(text_set_scaled[i, 0])                               #add apple data to LABELS \n",
        "    test.append(text_set_scaledX[i, 0])                              #add google data to LABELS\n",
        "    text_y.append(test)\n",
        "    test=[]\n",
        "    test.append(x[i])                                                #add apple labels with no normalization \n",
        "    test.append(x1[i])                                               #add google labels with no normalization \n",
        "    textY.append(test)\n",
        "\n",
        "\n",
        "textX, textY ,text_y = np.array(textX), np.array(textY), np.array(text_y)\n",
        "textX = np.reshape(textX, (textX.shape[0], textX.shape[1], 2))        # Reshaping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyxPfmiDc6WM"
      },
      "source": [
        "def drawTrainTrend(h):\n",
        "  plt.plot(h.history['mean_squared_error'], label='mean_squared_error (training data)')\n",
        "  plt.plot(h.history['val_mean_squared_error'], label='mean_squared_error (test data)')\n",
        "  # plt.title('train')\n",
        "  plt.ylabel('mean_squared_error value')\n",
        "  plt.xlabel('No. epoch')\n",
        "  plt.legend(loc=\"upper left\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(h.history['mean_absolute_percentage_error'], label='mean_absolute_percentage_error (training data)')\n",
        "  plt.plot(h.history['val_mean_absolute_percentage_error'], label='mean_absolute_percentage_error (test data)')\n",
        "  # plt.title('train')\n",
        "  plt.ylabel('mean_absolute_percentage_error value')\n",
        "  plt.xlabel('No. epoch')\n",
        "  plt.legend(loc=\"upper left\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yUZgLX7dNjq"
      },
      "source": [
        "def drawTestResults(real_stock_price,predicted_stock_price):\n",
        "  \n",
        "  predicted_stock_price1 = sc.inverse_transform(predicted_stock_price) # reverse apple data normalization\n",
        "  predicted_stock_priceX=scX.inverse_transform(predicted_stock_price) # reverse google data normalization\n",
        "  predicted_stock_price1=pd.DataFrame(predicted_stock_price1)\n",
        "  predicted_stock_priceX=pd.DataFrame(predicted_stock_priceX)\n",
        "\n",
        "  real_stock_price = np.reshape(real_stock_price, (real_stock_price.shape[0], real_stock_price.shape[1]))\n",
        "  real_stock_price=pd.DataFrame(real_stock_price)\n",
        "\n",
        "  plt.plot(real_stock_price[1], color = 'red', label = 'Real Google Stock Price')\n",
        "  plt.plot(predicted_stock_priceX[1], color = 'blue', label = 'Predicted Google Stock Price')\n",
        "  plt.title('Google Stock Price Prediction')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Google Stock Price')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(predicted_stock_price1[0], color = 'blue', label = 'Predicted APPLE Stock Price')\n",
        "  plt.plot(real_stock_price[0], color = 'red', label = 'Real Google Stock Price')\n",
        "  plt.title('APPLE Stock Price Prediction')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('APPLE Stock Price')\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dadnIQ4Oh6pV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b367f62-3f05-4e2f-d647-29db1f9ab7d9"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2007, 30, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WMpMiKZCe6T"
      },
      "source": [
        "def test(CellType,hasDrop,costFunction,optimization):  # create a rnn with cellType(GRU,LSTM,simpleRNN) and test\n",
        "  regressor = Sequential()\n",
        "  regressor.add(CellType(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 2)))\n",
        "  if(hasDrop):\n",
        "    regressor.add(Dropout(0.2))\n",
        "  regressor.add(CellType(units = 50, return_sequences = True))\n",
        "  if(hasDrop):\n",
        "    regressor.add(Dropout(0.2))\n",
        "\n",
        "  regressor.add(CellType(units = 50, return_sequences = True))\n",
        "  if(hasDrop):\n",
        "    regressor.add(Dropout(0.2))\n",
        "\n",
        "  regressor.add(CellType(units = 50))\n",
        "  if(hasDrop):\n",
        "    regressor.add(Dropout(0.2))\n",
        "\n",
        "  regressor.add(Dense(units = 2))\n",
        "\n",
        "  regressor.compile(optimizer = optimization, loss = costFunction ,metrics=['accuracy',\"mean_squared_error\",\"mean_absolute_percentage_error\"])\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  h=regressor.fit(X_train, y_train, epochs = 100, batch_size = 32,validation_data=(textX,text_y),verbose=True) #train\n",
        "  end = time.time()\n",
        "  print(end - start)\n",
        "  drawTrainTrend(h)\n",
        "\n",
        "  X_test = np.array(textX)\n",
        "  X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 2))\n",
        "  predicted_stock_price = regressor.predict(X_test)                                                             #test\n",
        "  drawTestResults(textY,predicted_stock_price)  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tk59F_QPEIQ"
      },
      "source": [
        "test(LSTM,True,'mean_squared_error','adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4PgG1KrZqjO"
      },
      "source": [
        "test(GRU,True,'mean_squared_error','adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCkDz916Z-Z8"
      },
      "source": [
        "test(SimpleRNN,True,'mean_squared_error','adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMdNCLC2U4Rc"
      },
      "source": [
        "test(GRU,True,'mean_squared_error','Adagrad')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NsM70ZhaQ_-"
      },
      "source": [
        "test(GRU,True,'mean_squared_error','RMSprop')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly8FLwoIepv7"
      },
      "source": [
        "test(GRU,False,'mean_squared_error','adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6pM5Imyeq6r"
      },
      "source": [
        "test(GRU,False,'mean_squared_error','Adagrad')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU1X_1Zweqj5"
      },
      "source": [
        "test(GRU,False,'mean_squared_error','RMSprop')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PBlnWnSVaRA"
      },
      "source": [
        "test(GRU,True,'mean_absolute_percentage_error','adam')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}